# Multi-Agent RAG System  
### (Groq + LangGraph + FastAPI + Streamlit + ChromaDB â€” powered by `uv` & Docker)

A fully local, production-style **Multi-Agent RAG workflow**, designed for backend engineers, ML enthusiasts, and system design learners.

This project demonstrates how to build a **real-world multi-agent system** with retrieval, summarization, and report generation â€” using only one external API (**Groq**, free key).

---

# âœ… 1. What Problem Are We Solving?

### âœ… **Use Case: E-commerce Competitor Analysis**
Companies often need to compare themselves with major competitors (Amazon, Flipkart, Walmart, Alibaba). Doing this manually requires:

- Searching online sources  
- Collecting competitor information  
- Summarizing insights  
- Combining everything into a structured report  

**This is slow, manual, and error-prone**.

### âœ… **Our Multi-Agent RAG System Automates This**
Given a topic like:

> **â€œAmazon competitor analysisâ€**

The system will:

1ï¸âƒ£ Perform targeted web research  
2ï¸âƒ£ Summarize each result  
3ï¸âƒ£ Store the research in a vector database  
4ï¸âƒ£ Retrieve context  
5ï¸âƒ£ Generate a final executive-level analytical report  

All orchestrated via a **LangGraph state machine**.

---

# âœ… 2. Architecture Overview

```
User Input â†’ Research Agent â†’ Index Agent â†’ Draft Agent â†’ Final RAG Report
```

Each step is a **LangGraph node** with defined responsibilities.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   User Input   â”‚
â”‚  "Nike ecommerce" 
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Research Agent        â”‚
â”‚  - Web search          â”‚
â”‚  - LLM summaries       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Index Agent           â”‚
â”‚  - Embed text          â”‚
â”‚  - Store in Chroma     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Draft Agent           â”‚
â”‚  - Retrieve context    â”‚
â”‚  - Generate report     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Final Competitor Reportâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# âœ… 3. Tools Used in the System

## âœ… LLM Tools

| Tool | Purpose |
|------|---------|
| **Groq Llama 3** | Ultra-fast summarization & report generation |
| **llm_chat wrapper** | Safe wrapper around Groq chat.completions |

## âœ… Retrieval Tools

| Tool | Purpose |
|------|---------|
| **simple_search (Tavily)** | Web search to fetch snippets |
| **HuggingFaceEmbeddings** | Convert text â†’ embeddings |
| **ChromaDB** | Local vector database for retrieval |

---

# âœ… 4. Agents & What Tools They Use

| Agent | Node Name | Responsibilities | Tools Used |
|--------|-----------|------------------|------------|
| **Research Agent** | `research` | Web search + summarization | `simple_search`, `llm_chat` |
| **Index Agent** | `index` | Embed text + store in vector DB | HF Embeddings, Chroma `add_texts()` |
| **Draft Agent** | `draft` | Retrieve context + generate final report | Chroma `retrieve()`, `llm_chat` |

---

# âœ… 5. LangGraph State Machine

### âœ… State Model

```python
class PipelineState(BaseModel):
    topic: str
    research_notes: List[str] = []
    indexed: bool = False
    context_snippets: List[str] = []
    final_report: Optional[str] = None
    error: Optional[str] = None
```

### âœ… Graph Nodes

| Node | Purpose |
|------|---------|
| `research` | Fetch data + summarize |
| `index` | Embed + store |
| `draft` | RAG + final report |

### âœ… Graph Structure

```
START â†’ research â†’ index â†’ draft â†’ END
```

---

# âœ… 6. Complete Tech Stack

- Python 3.11  
- uv  
- FastAPI  
- Streamlit  
- LangGraph  
- Groq LLM  
- ChromaDB  
- HuggingFace Sentence Transformers  

---

# âœ… 7. Running the System

## ğŸ“¦ Prereqs

- Docker + Docker Compose  
- Groq API key  

---

## âš™ï¸ Setup Environment

You only need **one** `.env` file depending on how you run the system:

### Option 1: Docker Compose (Recommended)

Create `.env` in the **root directory**:
```bash
cp .env.example .env
```

Edit the root `.env` file with your API keys:
```bash
GROQ_API_KEY=gsk_xxx
TAVILY_API_KEY=tvly_xxx
MODEL_NAME=llama-3.1-8b-instant
EMBED_MODEL=sentence-transformers/all-MiniLM-L6-v2
CHROMA_DIR=./data/chroma
BACKEND_HOST=backend
BACKEND_PORT=8000
```

### Option 2: Local Development

Create `.env` in the **backend/** directory:
```bash
cp .env.example backend/.env
```

Edit `backend/.env` with your API keys:
```bash
GROQ_API_KEY=gsk_xxx
TAVILY_API_KEY=tvly_xxx
MODEL_NAME=llama-3.1-8b-instant
EMBED_MODEL=sentence-transformers/all-MiniLM-L6-v2
CHROMA_DIR=./data/chroma
```

**Note**: You don't need both files - choose the location based on your deployment method.

---

# Run With Docker (Recommended)

```
docker compose up --build
```

Open:

- Backend: http://localhost:8000/docs  
- UI: http://localhost:8501  

---

# ğŸ›  Local Dev (Optional)

### Backend
```
cd backend
uv sync
uv run uvicorn app:app --reload --port 8000
```

### UI
```
cd ui
uv sync
uv run streamlit run streamlit_app.py
```

---

# âœ… 8. Notes

- ChromaDB persists to `./data/chroma`  
- Replace Groq with Ollama for full offline mode  
- Extend system with more agents (Planner, Validator, Router)  

---

# âœ… 9. Summary

This project demonstrates a real, production-grade:

âœ… Multi-Agent workflow  
âœ… Retrieval-Augmented Generation  
âœ… LangGraph orchestration  
âœ… Chroma-based local vector retrieval  
âœ… Groq Llama inference pipeline  
âœ… Fully local deployment via Docker  

